# -*- coding: utf-8 -*-
"""GradientMasking.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15GFiO5FUfXTDkQyQITMc3dhQqhrrxf7g
"""

import torch
from torch import nn, optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import torch.nn.functional as F
import numpy as np
from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent, BasicIterativeMethod
from art.estimators.classification import PyTorchClassifier

# Check if CUDA is available
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Training parameters
SEED = 1
N_EPOCHS = 1
BATCH_SIZE = 64
LEARNING_RATE = 0.001
N_CLASSES = 10  # CIFAR-10 has 10 classes

# Set the seed for reproducibility
torch.manual_seed(SEED)

# Load and transform the CIFAR-10 dataset
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)

test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)

# Define the ResNet-50 model
model = models.resnet50(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, N_CLASSES)
model = model.to(DEVICE)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

# Custom gradient masking layer
class GradientMaskingLayer(nn.Module):
    def __init__(self, masking_strength=0.5):
        super(GradientMaskingLayer, self).__init__()
        self.masking_strength = masking_strength

    def forward(self, x):
        return x

    def backward(self, grad_output):
        masked_grad = grad_output * (1 - self.masking_strength)
        return masked_grad

# Define a model with gradient masking
class MaskedModel(nn.Module):
    def __init__(self, base_model, masking_strength=0.5):
        super(MaskedModel, self).__init__()
        self.base_model = base_model
        self.gradient_masking_layer = GradientMaskingLayer(masking_strength)

    def forward(self, x):
        x = self.gradient_masking_layer(x)
        return self.base_model(x)

# Initialize the masked model
masked_model = MaskedModel(model, masking_strength=0.5).to(DEVICE)

# Training function
def train_model(model, train_loader, criterion, optimizer, n_epochs, device):
    model.train()
    for epoch in range(n_epochs):
        running_loss = 0.0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
        print(f'Epoch [{epoch + 1}/{n_epochs}], Loss: {running_loss / len(train_loader):.4f}')
    print('Finished Training')

# Test function
def test_model(model, test_loader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    print(f'Accuracy: {accuracy:.2f}%')
    return accuracy

# Train the masked model
train_model(masked_model, train_loader, criterion, optimizer, N_EPOCHS, DEVICE)

# Test the masked model
test_model(masked_model, test_loader, DEVICE)

# Define adversarial attacks with ART
classifier = PyTorchClassifier(
    model=model,
    loss=criterion,
    optimizer=optimizer,
    input_shape=(3, 224, 224),
    nb_classes=N_CLASSES,
)

fgm_attack = FastGradientMethod(estimator=classifier, eps=0.1)
pgd_attack = ProjectedGradientDescent(estimator=classifier, eps=0.3, eps_step=0.1, max_iter=40)
bim_attack = BasicIterativeMethod(estimator=classifier, eps=0.2, eps_step=0.05, max_iter=30)

# Generate adversarial examples
def generate_adversarial_examples(input_batch):
    fgm_adv = fgm_attack.generate(x=input_batch)
    pgd_adv = pgd_attack.generate(x=input_batch)
    bim_adv = bim_attack.generate(x=input_batch)
    return [fgm_adv, pgd_adv, bim_adv]

# Ensemble attack
def weighted_ensemble_attack(attacks, input_batch, weights=None):
    num_attacks = len(attacks)
    if weights is None:
        weights = [1 / num_attacks] * num_attacks
    combined_attack = np.zeros_like(input_batch)
    for i in range(num_attacks):
        combined_attack += attacks[i] * weights[i]
    return combined_attack

# Test against combined attack
def test_combined_attack(model, test_loader, device):
    correct = 0
    total = 0
    model.eval()
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        attacks = generate_adversarial_examples(images.cpu().numpy())
        combined_adv_images = weighted_ensemble_attack(attacks, images.cpu().numpy())
        combined_adv_images = torch.tensor(combined_adv_images).to(device)
        outputs = model(combined_adv_images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    print(f'Accuracy on combined adversarial test images: {accuracy:.2f}%')
    return accuracy

# Test the masked model against combined attack
test_combined_attack(masked_model, test_loader, DEVICE)